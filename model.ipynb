{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sharanya/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import keras_metrics as km\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = np.load(\"trainx0.npy\")\n",
    "x_train1 = np.load(\"trainx1.npy\")\n",
    "x_train2 = np.load(\"trainx2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = x_train0.reshape(1076, 300,300, 3).astype('float16') / 255\n",
    "x_train1 = x_train1.reshape(1072, 300,300, 3).astype('float16') / 255\n",
    "x_train2 = x_train0.reshape(1076, 300,300, 3).astype('float16') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test0 = x_train0[:269]\n",
    "y_test0 = np.zeros(269)\n",
    "\n",
    "x_val0 = x_train0[269:430]\n",
    "y_val0 = np.zeros(161)\n",
    "\n",
    "x_train0 = x_train0[430:]\n",
    "y_train0 = np.zeros(646)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = x_train1[:269]\n",
    "y_test1 = np.ones(269)\n",
    "\n",
    "x_val1 = x_train1[269:430]\n",
    "y_val1 = np.ones(161)\n",
    "\n",
    "x_train1 = x_train1[430:]\n",
    "y_train1 = np.ones(642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = x_train2[:269]\n",
    "y_test2 = np.ones(269) * 2\n",
    "\n",
    "x_val2 = x_train2[269:430]\n",
    "y_val2 = np.ones(161) * 2\n",
    "\n",
    "x_train2 = x_train2[430:]\n",
    "y_train2 = np.ones(646) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vali = np.append(x_val0, x_val1, axis=0)\n",
    "x_val = np.append(x_vali, x_val2, axis=0)\n",
    "\n",
    "x_testi = np.append(x_test0, x_test1, axis=0)\n",
    "x_test = np.append(x_testi, x_test2, axis=0)\n",
    "\n",
    "x_traini = np.append(x_train0, x_train1, axis=0)\n",
    "x_train = np.append(x_traini, x_train2, axis=0)\n",
    "\n",
    "\n",
    "y_vali = np.append(y_val0, y_val1, axis=0)\n",
    "y_val = np.append(y_vali, y_val2, axis=0)\n",
    "\n",
    "y_testi = np.append(y_test0, y_test1, axis=0)\n",
    "y_test = np.append(y_testi, y_test2, axis=0)\n",
    "\n",
    "y_traini = np.append(y_train0, y_train1, axis=0)\n",
    "y_train = np.append(y_traini, y_train2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 300, 300, 3)\n",
      "(807, 300, 300, 3)\n",
      "(1934, 300, 300, 3)\n",
      "(483,)\n",
      "(807,)\n",
      "(1934,)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_val)\n",
    "encoded_Y = encoder.transform(y_val)\n",
    "y_val_enc = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_Y = encoder.transform(y_test)\n",
    "y_test_enc = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train_enc = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, 300, 300)\n",
    "else:\n",
    "    input_shape = (300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,\n",
    "    y_train_enc,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val,y_val_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807/807 [==============================] - 108s 134ms/step\n",
      "test loss, test acc: [0.009961007923919817, 0.997521698474884]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test_enc, batch_size=128)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('x_train.npy',x_train)\n",
    "# np.save('x_test.npy',x_test)\n",
    "# np.save('x_val.npy',x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('y_train_enc.npy',y_train_enc)\n",
    "# np.save('y_test_enc.npy',y_test_enc)\n",
    "# np.save('y_val_enc.npy',y_val_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268   1   0]\n",
      " [  1 268   0]\n",
      " [  0   0 269]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       1.00      1.00      1.00       269\n",
      "      normal       1.00      1.00      1.00       269\n",
      "   pneumonia       1.00      1.00      1.00       269\n",
      "\n",
      "    accuracy                           1.00       807\n",
      "   macro avg       1.00      1.00      1.00       807\n",
      "weighted avg       1.00      1.00      1.00       807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['covid', 'normal', 'pneumonia']\n",
    "print(classification_report(y_test, Y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
